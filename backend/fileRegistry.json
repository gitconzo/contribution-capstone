[
  {
    "id": "COS4000 Worklog Week 6__1760925017013.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760925017013.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760925017013.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T01:50:17.027Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Worklog parse failed: Traceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 8, in extract_text_docx\n    from docx import Document\nModuleNotFoundError: No module named 'docx'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 92, in <module>\n    lines = extract_text_docx(in_path)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 10, in extract_text_docx\n    raise RuntimeError(\"python-docx not installed. pip install python-docx\")\nRuntimeError: python-docx not installed. pip install python-docx\n"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760925122301.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760925122301.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760925122301.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T01:52:02.318Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Worklog parse failed: Traceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 8, in extract_text_docx\n    from docx import Document\nModuleNotFoundError: No module named 'docx'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 92, in <module>\n    lines = extract_text_docx(in_path)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/worklog_parser.py\", line 10, in extract_text_docx\n    raise RuntimeError(\"python-docx not installed. pip install python-docx\")\nRuntimeError: python-docx not installed. pip install python-docx\n"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760925315876.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760925315876.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760925315876.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T01:55:15.893Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/COS4000 Worklog Week 6__1760925315876.json",
      "message": "Worklog parsed"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760925636272.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760925636272.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760925636272.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T02:00:36.282Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/COS4000 Worklog Week 6__1760925636272.json",
      "message": "Worklog parsed"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760936288082.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760936288082.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760936288082.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T04:58:08.097Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/COS4000 Worklog Week 6__1760936288082.json",
      "message": "Worklog parsed"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760937419032.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760937419032.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760937419032.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T05:16:59.048Z",
    "detectedType": "worklog",
    "userType": null,
    "status": "uploaded",
    "parseInfo": null
  },
  {
    "id": "COS4000 Worklog Week 9__1760938714775.pdf",
    "originalName": "COS4000 Worklog Week 9.pdf",
    "storedName": "COS4000 Worklog Week 9__1760938714775.pdf",
    "storedPath": "uploads/COS4000 Worklog Week 9__1760938714775.pdf",
    "mimetype": "application/pdf",
    "size": 3078054,
    "uploadDate": "2025-10-20T05:38:34.786Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Worklog parse failed: Error: Package not found at '/Users/conzo/Desktop/contribution-capstone/backend/uploads/COS4000 Worklog Week 9__1760938714775.pdf'\n"
    }
  },
  {
    "id": "COS4000 Worklog Week 6__1760938744911.docx",
    "originalName": "COS4000 Worklog Week 6.docx",
    "storedName": "COS4000 Worklog Week 6__1760938744911.docx",
    "storedPath": "uploads/COS4000 Worklog Week 6__1760938744911.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 3514181,
    "uploadDate": "2025-10-20T05:39:04.925Z",
    "detectedType": "worklog",
    "userType": "worklog",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/COS4000 Worklog Week 6__1760938744911.json",
      "message": "Worklog parsed"
    }
  },
  {
    "id": "COS40005 Sprint 2 Report(1)__1761478414953.docx",
    "originalName": "COS40005 Sprint 2 Report(1).docx",
    "storedName": "COS40005 Sprint 2 Report(1)__1761478414953.docx",
    "storedPath": "uploads/COS40005 Sprint 2 Report(1)__1761478414953.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 9296340,
    "uploadDate": "2025-10-26T11:33:34.982Z",
    "detectedType": "sprint_report",
    "userType": "sprint_report",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Sprint report parse failed: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n    from pandas.compat import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 29, in <module>\n    from pandas.compat.pyarrow import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n    import pyarrow as pa\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n    from pandas.core.api import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n    from pandas.core.dtypes.dtypes import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n    from pandas._libs import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 15, in <module>\n    from nltk.parse import ParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/__init__.py\", line 100, in <module>\n    from nltk.parse.transitionparser import TransitionParser\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/transitionparser.py\", line 18, in <module>\n    from sklearn import svm\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 20, in <module>\n    from .utils._missing import is_scalar_nan\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 26, in <module>\n    parse_sprint_report(input_file)\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 13, in parse_sprint_report\n    result = parse_docx_with_metrics(docx_path, output_json_path=out_path)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 283, in parse_docx_with_metrics\n    students = build_student_metrics(authorship_map, extracted_sections)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 239, in build_student_metrics\n    \"metrics\": get_text_metrics(full_text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 46, in get_text_metrics\n    sentences = sent_tokenize(cleaned)\n                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 119, in sent_tokenize\n    tokenizer = _get_punkt_tokenizer(language)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 105, in _get_punkt_tokenizer\n    return PunktTokenizer(language)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1744, in __init__\n    self.load_lang(lang)\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1749, in load_lang\n    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/data.py\", line 579, in find\n    raise LookupError(resource_not_found)\nLookupError: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/conzo/nltk_data'\n    - '/Users/conzo/anaconda3/nltk_data'\n    - '/Users/conzo/anaconda3/share/nltk_data'\n    - '/Users/conzo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n\n"
    }
  },
  {
    "id": "COS40005 Sprint 2 Report(1)__1761484933447.docx",
    "originalName": "COS40005 Sprint 2 Report(1).docx",
    "storedName": "COS40005 Sprint 2 Report(1)__1761484933447.docx",
    "storedPath": "uploads/COS40005 Sprint 2 Report(1)__1761484933447.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 9296340,
    "uploadDate": "2025-10-26T13:22:13.476Z",
    "detectedType": "sprint_report",
    "userType": "sprint_report",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Sprint report parse failed: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n    from pandas.compat import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 29, in <module>\n    from pandas.compat.pyarrow import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n    import pyarrow as pa\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n    from pandas.core.api import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n    from pandas.core.dtypes.dtypes import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n    from pandas._libs import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 15, in <module>\n    from nltk.parse import ParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/__init__.py\", line 100, in <module>\n    from nltk.parse.transitionparser import TransitionParser\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/transitionparser.py\", line 18, in <module>\n    from sklearn import svm\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 20, in <module>\n    from .utils._missing import is_scalar_nan\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 26, in <module>\n    parse_sprint_report(input_file)\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 13, in parse_sprint_report\n    result = parse_docx_with_metrics(docx_path, output_json_path=out_path)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 283, in parse_docx_with_metrics\n    students = build_student_metrics(authorship_map, extracted_sections)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 239, in build_student_metrics\n    \"metrics\": get_text_metrics(full_text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 46, in get_text_metrics\n    sentences = sent_tokenize(cleaned)\n                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 119, in sent_tokenize\n    tokenizer = _get_punkt_tokenizer(language)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 105, in _get_punkt_tokenizer\n    return PunktTokenizer(language)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1744, in __init__\n    self.load_lang(lang)\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1749, in load_lang\n    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/data.py\", line 579, in find\n    raise LookupError(resource_not_found)\nLookupError: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/conzo/nltk_data'\n    - '/Users/conzo/anaconda3/nltk_data'\n    - '/Users/conzo/anaconda3/share/nltk_data'\n    - '/Users/conzo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n\n"
    }
  },
  {
    "id": "COS40005 Sprint 2 Report(1)__1761485330902.docx",
    "originalName": "COS40005 Sprint 2 Report(1).docx",
    "storedName": "COS40005 Sprint 2 Report(1)__1761485330902.docx",
    "storedPath": "uploads/COS40005 Sprint 2 Report(1)__1761485330902.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 9296340,
    "uploadDate": "2025-10-26T13:28:50.921Z",
    "detectedType": "sprint_report",
    "userType": "sprint_report",
    "status": "parse_failed",
    "parseInfo": {
      "message": "Sprint report parse failed: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n    from pandas.compat import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 29, in <module>\n    from pandas.compat.pyarrow import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n    import pyarrow as pa\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n    import pandas as pd\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n    from pandas.core.api import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n    from pandas.core.dtypes.dtypes import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n    from pandas._libs import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n    from nltk.chunk.util import ChunkScore\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n    from nltk.tag.mapping import map_tag\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n    from nltk.tag.sequential import (\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n    from nltk.classify import NaiveBayesClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n    from nltk.classify.scikitlearn import SklearnClassifier\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n    from sklearn.feature_extraction import DictVectorizer\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.4 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 3, in <module>\n    from parse_docx_with_metrics import parse_docx_with_metrics\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 5, in <module>\n    import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/__init__.py\", line 1, in <module>\n    from .textstat import textstat\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/textstat.py\", line 5, in <module>\n    from .backend import transformations, validations, selections, counts, metrics, utils\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/__init__.py\", line 1, in <module>\n    from . import counts\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/__init__.py\", line 1, in <module>\n    from ._count_chars import count_chars\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/counts/_count_chars.py\", line 5, in <module>\n    from ..utils._typed_cache import typed_cache\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/__init__.py\", line 1, in <module>\n    from ._get_cmudict import get_cmudict\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/textstat/backend/utils/_get_cmudict.py\", line 3, in <module>\n    import nltk\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n    from nltk.chunk import *\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n    from nltk.chunk.api import ChunkParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/chunk/api.py\", line 15, in <module>\n    from nltk.parse import ParserI\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/__init__.py\", line 100, in <module>\n    from nltk.parse.transitionparser import TransitionParser\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/parse/transitionparser.py\", line 18, in <module>\n    from sklearn import svm\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n    from .base import clone  # noqa: E402\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 20, in <module>\n    from .utils._missing import is_scalar_nan\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n    from ._chunking import gen_batches, gen_even_slices\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n    from ._param_validation import Interval, validate_params\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n    from .validation import _is_arraylike_not_scalar\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n    from .fixes import parse_version\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 421, in <module>\n    import pyarrow\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n    import pyarrow.lib as _lib\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 26, in <module>\n    parse_sprint_report(input_file)\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_sprint_report_docx.py\", line 13, in parse_sprint_report\n    result = parse_docx_with_metrics(docx_path, output_json_path=out_path)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 283, in parse_docx_with_metrics\n    students = build_student_metrics(authorship_map, extracted_sections)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 239, in build_student_metrics\n    \"metrics\": get_text_metrics(full_text)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/Desktop/contribution-capstone/backend/parsers/parse_docx_with_metrics.py\", line 46, in get_text_metrics\n    sentences = sent_tokenize(cleaned)\n                ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 119, in sent_tokenize\n    tokenizer = _get_punkt_tokenizer(language)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py\", line 105, in _get_punkt_tokenizer\n    return PunktTokenizer(language)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1744, in __init__\n    self.load_lang(lang)\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/tokenize/punkt.py\", line 1749, in load_lang\n    lang_dir = find(f\"tokenizers/punkt_tab/{lang}/\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/conzo/anaconda3/lib/python3.11/site-packages/nltk/data.py\", line 579, in find\n    raise LookupError(resource_not_found)\nLookupError: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/Users/conzo/nltk_data'\n    - '/Users/conzo/anaconda3/nltk_data'\n    - '/Users/conzo/anaconda3/share/nltk_data'\n    - '/Users/conzo/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n\n"
    }
  },
  {
    "id": "COS40005 Sprint 2 Report(1)__1761485865368.docx",
    "originalName": "COS40005 Sprint 2 Report(1).docx",
    "storedName": "COS40005 Sprint 2 Report(1)__1761485865368.docx",
    "storedPath": "uploads/COS40005 Sprint 2 Report(1)__1761485865368.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 9296340,
    "uploadDate": "2025-10-26T13:37:45.389Z",
    "detectedType": "sprint_report",
    "userType": "sprint_report",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/sprint_report_summary.json",
      "message": "Sprint report parsed successfully"
    }
  },
  {
    "id": "COS40005 Sprint 2 Report(1)__1761487411057.docx",
    "originalName": "COS40005 Sprint 2 Report(1).docx",
    "storedName": "COS40005 Sprint 2 Report(1)__1761487411057.docx",
    "storedPath": "uploads/COS40005 Sprint 2 Report(1)__1761487411057.docx",
    "mimetype": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "size": 9296340,
    "uploadDate": "2025-10-26T14:03:31.078Z",
    "detectedType": "sprint_report",
    "userType": "sprint_report",
    "status": "parsed",
    "parseInfo": {
      "jsonPath": "uploads/sprint_report_summary.json",
      "message": "Sprint report parsed successfully"
    }
  }
]